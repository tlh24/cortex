{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Explore model\n",
    "\n",
    "note - do `sh run.sh` before running this notebook as it needs to talk to that process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import mmap\n",
    "import torch as th\n",
    "from torch import nn, optim\n",
    "import torch.cuda.amp\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from ctypes import *\n",
    "import socket\n",
    "import time\n",
    "import clip_model\n",
    "import argparse\n",
    "import io\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "import torch._dynamo as dynamo\n",
    "dynamo.config.verbose=True\n",
    "# note: I can't seem to get this to work. tlh April 7 2023\n",
    "\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:512\n",
      "dreaming:False\n",
      "Received b'ok 0'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patch_size = 5\n",
    "v_ctx = int((image_res / patch_size) ** 2 + 1)\n",
    "vision_width = 256\n",
    "prog_width = 256\n",
    "vision_heads = 8\n",
    "vision_layers = 6\n",
    "prog_heads = 8\n",
    "prog_layers = 8\n",
    "embed_dim = 256\n",
    "\n",
    "train_iters = 100000\n",
    "learning_rate = 0.0005 # 1e-3 maximum learning rate. scheduled.\n",
    "# learning rate of 0.002 is unstable.  Should figure out why. \n",
    "weight_decay = 2.5e-6\n",
    "nreplace = 0\n",
    "batch_size = 512\n",
    "g_dreaming = False\n",
    "g_training = not g_dreaming\n",
    "print(f\"batch_size:{batch_size}\")\n",
    "print(f\"dreaming:{g_dreaming}\")\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "if g_dreaming: \n",
    "\tsock.connect(('127.0.0.1', 4341))\n",
    "else:\n",
    "\tsock.connect(('127.0.0.1', 4340))\n",
    "sock.sendall(b\"update_batch\")\n",
    "data = sock.recv(1024)\n",
    "print(f\"Received {data!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_mmf(fname): \n",
    "\tfd = open(fname, \"r+b\")\n",
    "\treturn mmap.mmap(fd.fileno(), 0)\n",
    "\n",
    "def read_mmap(mmf, dims): \n",
    "\tmmf.seek(0)\n",
    "\tmmb = mmf.read()\n",
    "\tsiz = len(mmb)\n",
    "\tmmb2 = (c_char * siz).from_buffer_copy(mmb)\n",
    "\tx = th.frombuffer(mmb2, dtype=th.float).clone()\n",
    "\tx = th.reshape(x, dims)\n",
    "\treturn x\n",
    "\t\n",
    "def write_mmap(mmf, data): \n",
    "\tq = data.detach().cpu().numpy().tobytes()\n",
    "\tmmf.seek(0)\n",
    "\tn = mmf.write(q)\n",
    "\treturn n\n",
    "\n",
    "if g_dreaming: \n",
    "\tmmapno = 1\n",
    "else:\n",
    "\tmmapno = 0\n",
    "\n",
    "edsiz = batch_size * e_indim * 4\n",
    "os.system(f\"fallocate -l {edsiz} editdiff_{mmapno}.mmap\")\n",
    "# the other mmaps are allocated by ocaml.\n",
    "\t\n",
    "fd_bpro = make_mmf(f\"bpro_{mmapno}.mmap\")\n",
    "fd_bimg = make_mmf(f\"bimg_{mmapno}.mmap\")\n",
    "fd_bedts = make_mmf(f\"bedts_{mmapno}.mmap\")\n",
    "fd_bedtd = make_mmf(f\"bedtd_{mmapno}.mmap\")\n",
    "fd_editdiff = make_mmf(f\"editdiff_{mmapno}.mmap\")\n",
    "fd_posenc = make_mmf(f\"posenc_{mmapno}.mmap\")\n",
    "posenc = read_mmap(fd_posenc, [p_ctx, poslen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch cuda devices 1\n",
      "torch device NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch_device = 0\n",
    "print(\"torch cuda devices\", th.cuda.device_count())\n",
    "print(\"torch device\", th.cuda.get_device_name(torch_device))\n",
    "th.cuda.set_device(torch_device)\n",
    "th.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "th.set_float32_matmul_precision('high') # desktop.\n",
    "\n",
    "def build_attention_mask(v_ctx, p_ctx):\n",
    "\t# allow the model to attend to everything when predicting an edit\n",
    "\t# causalty is enforced by the editing process.\n",
    "\t# see ec31.py for a causal mask.\n",
    "\tctx = v_ctx + p_ctx\n",
    "\tmask = th.ones(ctx, ctx)\n",
    "\treturn mask\n",
    "\n",
    "\n",
    "class ecTransformer(nn.Module):\n",
    "\tdef __init__(self, image_resolution: int, vision_width:int, patch_size:int,  prog_width:int, embed_dim:int, v_ctx:int, p_ctx:int, p_indim:int, e_indim:int): \n",
    "\t\tsuper().__init__()\n",
    "\t\tself.v_ctx = v_ctx\n",
    "\t\tself.p_ctx = p_ctx\n",
    "\t\tself.p_indim = p_indim\n",
    "\t\t\n",
    "\t\tself.vit = clip_model.VisionTransformer(\n",
    "\t\t\tinput_resolution = image_resolution, \n",
    "\t\t\tpatch_size = patch_size, \n",
    "\t\t\twidth = vision_width, \n",
    "\t\t\tlayers = 4, \n",
    "\t\t\theads = 8, \n",
    "\t\t\toutput_dim = embed_dim)\n",
    "\n",
    "\t\tself.vit_to_prt = nn.Linear(embed_dim, prog_width)\n",
    "\t\t\n",
    "\t\tself.encoder = nn.Linear(p_indim, prog_width)\n",
    "\t\tself.prt = clip_model.Transformer(\n",
    "\t\t\twidth = prog_width, \n",
    "\t\t\tlayers = 6, \n",
    "\t\t\theads = 8, \n",
    "\t\t\tattn_mask = build_attention_mask(v_ctx, p_ctx))\n",
    "\t\t\t\n",
    "\t\tself.prt_to_edit = nn.Linear(prog_width * (p_ctx + v_ctx), e_indim)\n",
    "\t\tself.ln_post = clip_model.LayerNorm(e_indim)\n",
    "\t\tself.gelu = clip_model.QuickGELU()\n",
    "\t\tself.tok_softmax = nn.Softmax(dim = 1)\n",
    "\t\n",
    "\tdef forward(self, u, batch_a, batch_p): \n",
    "\t\t# encode the image (we should only need to do this once??)\n",
    "\t\tq = th.zeros(6) # ! this will be parallelized !\n",
    "\t\tvx = self.vit(batch_a) # x is size [bs, v_ctx, 256] \n",
    "\t\tq[0] = th.std(vx)\n",
    "\t\tvx = self.vit_to_prt(vx)\n",
    "\t\tq[1] = th.std(vx)\n",
    "\t\t# vx = gelu(vx) # ? needed ? \n",
    "\n",
    "\t\tpx = self.encoder(batch_p)\n",
    "\t\tq[2] = th.std(px)\n",
    "\t\tvxpx = th.cat((vx, px), dim = 1)\n",
    "\t\tq[3] = th.std(vxpx)\n",
    "\t\t# x = vxpx * mask\n",
    "\t\tx = self.prt(vxpx) # bs, v_ctx + p_ctx, prog_width\n",
    "\t\tq[4] = th.std(x)\n",
    "\t\tx = th.reshape(x, (-1,(v_ctx + p_ctx)*prog_width))\n",
    "\t\t# batch size will vary with dataparallel\n",
    "\t\tx = self.prt_to_edit(x)\n",
    "\t\tq[5] = th.std(x)\n",
    "\t\t# x = self.ln_post(x) # scale the inputs to softmax\n",
    "\t\t# x = self.gelu(x)\n",
    "\t\t# x = th.cat((self.tok_softmax(x[:,0:4]),\n",
    "\t\t# \t\t  self.tok_softmax(x[:,4:4+toklen]), \n",
    "\t\t# \t\t  x[:,4+toklen:]), dim=1) -- this is for fourier position enc. \n",
    "\t\treturn x,q\n",
    "\n",
    "model = ecTransformer(image_resolution = image_res, \n",
    "\t\t\t\t\t\t\t vision_width = vision_width, \n",
    "\t\t\t\t\t\t\t patch_size = patch_size, \n",
    "\t\t\t\t\t\t\t prog_width = prog_width, \n",
    "\t\t\t\t\t\t\t embed_dim = embed_dim, \n",
    "\t\t\t\t\t\t\t v_ctx = v_ctx, \n",
    "\t\t\t\t\t\t\t p_ctx = p_ctx, \n",
    "\t\t\t\t\t\t\t p_indim = p_indim, \n",
    "\t\t\t\t\t\t\t e_indim = e_indim)\n",
    "\n",
    "from os.path import exists\n",
    "if exists(\"ec32.ptx\"):\n",
    "\tloaded_dict = torch.load(\"ec32.ptx\")\n",
    "\tmodel.load_state_dict(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters:9.807817M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainable_params = sum(\n",
    "\tp.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(f\"Number of model parameters:{trainable_params/1e6}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lossfunc_cel = nn.CrossEntropyLoss(label_smoothing = 0.08, reduction='mean')\n",
    "lossfunc_mse = nn.MSELoss(reduction='mean')\n",
    "# optimizer = optim.SGD(model.parameters(), lr=2e-3)\n",
    "# !SGD does not work!  AdamW much better.  \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "def print_model_params(): \n",
    "\tprint(model.prt_to_tok.weight[0,:])\n",
    "\tprint(model.prt.resblocks[0].mlp[0].weight[0,:])\n",
    "\tprint(model.vit_to_prt.weight[0,1:20])\n",
    "\tprint(model.vit.transformer.resblocks[0].mlp[0].weight[0,1:20])\n",
    "\tprint(model.vit.conv1.weight[0,:])\n",
    "\t# it would seem that all the model parameters are changing.\n",
    "\n",
    "def std_model_params(): \n",
    "\tq = th.zeros(5)\n",
    "\tq[0] = th.std(model.vit.conv1.weight)\n",
    "\tq[1] = th.std(model.vit.transformer.resblocks[0].mlp[0].weight)\n",
    "\tq[2] = th.std(model.vit_to_prt.weight)\n",
    "\tq[3] = th.std(model.prt.resblocks[0].mlp[0].weight)\n",
    "\tq[4] = th.std(model.prt_to_tok.weight)\n",
    "\treturn q\n",
    "\t\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "slowloss = 1.0\n",
    "losslog = open(\"loss_log.txt\", \"w\")\n",
    "lr = learning_rate\n",
    "tic = time.time()\n",
    "if g_training:\n",
    "\tprint(\"training...\")\n",
    "if g_dreaming:\n",
    "\tprint(\"dreaming...\")\n",
    "\n",
    "# compiling this does not seem to work... \n",
    "def train(mod, bimg, bpro, bedts): \n",
    "\tmodel.zero_grad()\n",
    "\ty,q = model(u, bimg, bpro)\n",
    "\tloss = lossfunc(y, bedts)\n",
    "\tlossflat = th.sum(loss)\n",
    "\tlossflat.backward()\n",
    "\tth.nn.utils.clip_grad_norm_(model.parameters(), 0.025)\n",
    "\toptimizer.step()\n",
    "\treturn y,q,lossflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecTransformer(\n",
       "  (vit): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 256, kernel_size=(5, 5), stride=(5, 5), bias=False)\n",
       "    (ln_pre): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vit_to_prt): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (encoder): Linear(in_features=63, out_features=256, bias=True)\n",
       "  (prt): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prt_to_edit): Linear(in_features=25856, out_features=67, bias=True)\n",
       "  (ln_post): LayerNorm((67,), eps=1e-05, elementwise_affine=True)\n",
       "  (gelu): QuickGELU()\n",
       "  (tok_softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = 0\n",
    "# keep things synchronous for now. \n",
    "sock.sendall(b\"update_batch\")\n",
    "data = sock.recv(100) # faster? \n",
    "\n",
    "bpro = read_mmap(fd_bpro, [batch_size, p_ctx, p_indim])\n",
    "bimg = read_mmap(fd_bimg, [batch_size, 3, image_res, image_res])\n",
    "bedts = read_mmap(fd_bedts, [batch_size, e_indim])\n",
    "\n",
    "if th.min(bedts[:,0]) < 0: \n",
    "    print(\"bedts synchronization issue!\")\n",
    "    \n",
    "if g_dreaming: \n",
    "    bimg = bimg.cuda()\n",
    "    bimg = bimg + th.randn(batch_size, 3, image_res, image_res) * 0.1\n",
    "else:\n",
    "    bimg = bimg.cuda()\n",
    "\n",
    "# with th.autocast(device_type='cuda', dtype=torch.float16):\n",
    "model.zero_grad()\n",
    "y,q = model(u, bimg, bpro.cuda())\n",
    "if g_training: \n",
    "    # y,q,lossflat = train(model, bimg, bpro.cuda(), bedts.cuda())\n",
    "    targ = bedts.cuda()\n",
    "    loss = lossfunc_mse(y, targ)\n",
    "    # loss_typ = lossfunc_cel(y[:,0:4], targ[:,0:4])\n",
    "    # loss_chr = lossfunc_cel(y[:,4:4+toklen], targ[:,4:4+toklen])\n",
    "    # loss_pos = lossfunc_mse(y[:,5+toklen:], targ[:,5+toklen:])\n",
    "    # loss = loss_typ + loss_chr + loss_pos # should be batch_size\n",
    "    lossflat = th.sum(loss)\n",
    "    lossflat.backward()\n",
    "    th.nn.utils.clip_grad_norm_(model.parameters(), 0.025)\n",
    "    optimizer.step() \n",
    "    lossflat.detach()\n",
    "else: \n",
    "    lossflat = 0.0\n",
    "    \n",
    "slowloss = 0.99*slowloss + 0.01 * lossflat\n",
    "# ngpu = th.cuda.device_count()\n",
    "# q = th.reshape(q, (ngpu,-1)) \n",
    "# q = th.mean(q, 0) # only for model DP. \n",
    "if g_training: \n",
    "    losslog.write(f\"{u}\\t{slowloss}\")\n",
    "    for i in range(q.shape[0]): \n",
    "        losslog.write(f\"\\t{q[i].cpu().item()}\")\n",
    "    losslog.write(f\"\\t{nreplace+0.001}\")\n",
    "    losslog.write(\"\\n\")\n",
    "    losslog.flush()\n",
    "\n",
    "write_mmap(fd_bedtd, y)\n",
    "if g_training: \n",
    "    write_mmap(fd_editdiff, bedts - y.cpu()) # synchronization.\n",
    "    sock.sendall(b\"decode_edit\")\n",
    "    data = sock.recv(100)\n",
    "# scaler.scale(lossflat).backward()\n",
    "# th.nn.utils.clip_grad_norm_(model.parameters(), 0.05)\n",
    "# scaler.step(optimizer)\n",
    "# scaler.update()\n",
    "\n",
    "if u % 11 == 0 :\n",
    "    toc = time.time()\n",
    "    rate = int((batch_size * 11) / (toc - tic))\n",
    "    tic = toc\n",
    "    print(f'{u} {lr:.6f} loss: {lossflat:.5f}; slowloss {slowloss:.5f}; {rate} samp/sec')\n",
    "\n",
    "# change the learning rate. \n",
    "if False: \n",
    "    lr = learning_rate\n",
    "    # ramp up between 1000 and 11000\n",
    "    if u > 1000:\n",
    "        lr = lr * (1 + ((u-1000) / 5000))\n",
    "    lr = min(lr, 0.001) # this seems to be the outright maximum\n",
    "    # decay from 11k to end\n",
    "    if u > 11000: \n",
    "        lr = lr * math.exp((11000-u) / 50000)\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "            \n",
    "if u % 1000 == 999 : \n",
    "    if g_training: \n",
    "        torch.save(model.state_dict(), \"ec32.ptx\")\n",
    "        print(\"saved ec32.ptx\")\n",
    "    if g_dreaming: \n",
    "        loaded_dict = torch.load(\"ec32.ptx\")\n",
    "        model.load_state_dict(loaded_dict)\n",
    "        print(\"dreamer reloaded model parameters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec3-mMuvAcn9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
